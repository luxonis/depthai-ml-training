{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Easy_Object_Detection_With_Custom_Data_Demo_Training.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJz_ToJtkufM"
   },
   "source": [
    "# DepthAI Tutorial: Training an Object Detection Model with Your Own Data\n",
    "\n",
    "<img src=\"https://docs.luxonis.com/images/depthai_logo.png\" width=\"500\">\n",
    "\n",
    "Welcome to DepthAI! \n",
    "\n",
    "In this tutorial we will go through the basic training of an object detection model with your own annotated images.\n",
    "\n",
    "The model you will use is a pretrained Mobilenet SSD v2 from the Tensorflow Object Detection API model zoo. The framework used for training is TensorFlow 1.15.2.\n",
    "Will run through the following steps:\n",
    "\n",
    "\n",
    "*   Install the libraries\n",
    "*   Clone the github repo and replace the repo training data with your data from google drive\n",
    "    (if you do not have own data, please see this\n",
    "*   Train the model on the new images\n",
    "*   Run inference on a few images to see what the model can detect\n",
    "*   Convert the model to OpenVINO Intermediate Representation\n",
    "*   To run the model on DepthAI modules, compile the IR obtained above to a .blob file \n",
    "\n",
    "You can make a copy of this tutorial: File-> Save a copy in Drive\n",
    "\n",
    "Note: the model training can be run with the repo images of three fruits if you choose to skip the part with loading your own images\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmw4ac-EQuzj"
   },
   "source": [
    "# Install Libraries\n",
    "# Press Shift+Enter to run cells\n",
    "Some cells are commented out (all text is green), so they will not run the code inside.\n",
    "To uncomment code inside a cell, select all the code then press 'Ctrl' + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVmWjRMLlR3l"
   },
   "source": [
    "###After this cell executes runtime will restart to complete the install, ignore and close the message, continue running the cells below this one\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pH1x08R-yM-L",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "483431af-3266-47c8-dc9e-f49f30c1f082"
   },
   "source": [
    "# %%capture\n",
    "#After this cell executes runtime will restart to finish the install, ignore and close the crash message, continue running cells starting with the one below\n",
    "!pip install numpy==1.17.5;"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.17.5 in /usr/local/lib/python3.7/dist-packages (1.17.5)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9z8kgcs0E7iV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2615dc36-1a01-41f3-c95d-4f02f3893e04"
   },
   "source": [
    "%tensorflow_version 1.x\n",
    "!pip install tf_slim"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gnNXNQCjdniL"
   },
   "source": [
    "# For the fruit model included in the repo below we have 240 training images\n",
    "# For faster training time, images should be resized to 300x300 and then annotated\n",
    "# Images should contain the objects of interest at various scales, angles, lighting conditions, locations\n",
    "# For acceptable results - mAP@0.5 of 0.9 the model was trained with batch size of 24\n",
    "# and 5000 steps. this takes about 1h using 2 augmentations. \n",
    "# using 5 augmentations it takes about 2h \n",
    "num_steps = 5000  # A step means using a single batch of data. larger batch, less steps required\n",
    "#Number of evaluation steps.\n",
    "num_eval_steps = 50\n",
    "#Batch size 24 is a setting that generally works well. can be changed higher or lower \n",
    "MODELS_CONFIG = {\n",
    "        'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 24\n",
    "    }\n",
    "}\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colab's GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4V-XE6kbkc1"
   },
   "source": [
    "## Clone the `object_detection_demo_flow` repository"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dxc3DmvLQF3z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39166102-bc61-4679-ea61-7b15672fbbd4"
   },
   "source": [
    "repo_url = 'https://github.com/GotG/object_detection_demo_flow'\n",
    "import os\n",
    "%cd /content\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "!rm -rf {repo_dir_path}\n",
    "!git clone {repo_url} {repo_dir_path}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into '/content/object_detection_demo_flow'...\n",
      "remote: Enumerating objects: 3035, done.\u001B[K\n",
      "remote: Total 3035 (delta 0), reused 0 (delta 0), pack-reused 3035\u001B[K\n",
      "Receiving objects: 100% (3035/3035), 229.08 MiB | 25.01 MiB/s, done.\n",
      "Resolving deltas: 100% (1375/1375), done.\n",
      "Checking out files: 100% (2796/2796), done.\n",
      "/content/object_detection_demo_flow\n",
      "Already up to date.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LnZjgF4N71_"
   },
   "source": [
    "#[Optional] If you wish to use your own data, run the cells below.\n",
    "(Otherwise the model can train with the data already present in the cloned repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPVANnM4QUWT"
   },
   "source": [
    "## Mount your google drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KPahiXuPNQwX"
   },
   "source": [
    "#mount your google drive.\n",
    "#it will be visible in the file navigator on the left of this notebook\n",
    "#there should be a folder in your drive with your data\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2ZtJqdRsV0A"
   },
   "source": [
    "Own data should be split into 80% training (train folder), 20% for validation (test folder). The train and test folder should contain images and associated .xml annotations. \n",
    "\n",
    "Have extra images for final model testing (final_test folder). These need not be annotated.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4JlG_0vgOB_F",
    "outputId": "60d8aff5-e264-42cc-a7af-d7c93d65989a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#To train on your own data:\n",
    "#Remove repo data (images) for training/testing/final testing\n",
    "!rm -r /content/object_detection_demo_flow/data/images/final_test/\n",
    "!rm -r /content/object_detection_demo_flow/data/images/train/\n",
    "!rm -r /content/object_detection_demo_flow/data/images/test/"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/object_detection_demo_flow/data/images/final_test/': No such file or directory\n",
      "rm: cannot remove '/content/object_detection_demo_flow/data/images/train/': No such file or directory\n",
      "rm: cannot remove '/content/object_detection_demo_flow/data/images/test/': No such file or directory\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gsUxoYiDOYwr",
    "outputId": "b50fabff-add6-4d98-b2d6-d5e7390cc065",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#copy files from gdrive to colab drive. this takes a few minutes, depending on the number of files.\n",
    "#Go on the file explorer on the left of this notebook and access your gdrive. find the folders\n",
    "#with your train, test and final_test images.\n",
    "#Right click on each and copy the path. paste it btw the first \" \" in the corresponding lines  \n",
    "\n",
    "#training folder\n",
    "!cp -r \"/content/gdrive/My Drive/data/3fruit/train_fruit/\" \"/content/object_detection_demo_flow/data/images/train\"\n",
    "#testing folder\n",
    "!cp -r \"/content/gdrive/My Drive/data/3fruit/test_fruit/\" \"/content/object_detection_demo_flow/data/images/test\"\n",
    "#final testing folder\n",
    "!cp -r \"/content/gdrive/My Drive/data/3fruit/final_test_fruit/\" \"/content/object_detection_demo_flow/data/images/final_test\""
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/content/gdrive/My Drive/data/3fruit/train_fruit/': No such file or directory\n",
      "cp: cannot stat '/content/gdrive/My Drive/data/3fruit/test_fruit/': No such file or directory\n",
      "cp: cannot stat '/content/gdrive/My Drive/data/3fruit/final_test_fruit/': No such file or directory\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pHUcVDSEfuCE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a894b8d-bdaf-4931-9cf2-a89eef58d8a6"
   },
   "source": [
    "# quick check for training data files. you can also browse to the object_detection_demo_flows\n",
    "# on the left and see if they were copied\n",
    "!ls /content/object_detection_demo_flow/data/images/train"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "apple_10.jpg  apple_55.jpg   banana_32.jpg  banana_76.jpg  orange_32.jpg\n",
      "apple_10.xml  apple_55.xml   banana_32.xml  banana_76.xml  orange_32.xml\n",
      "apple_11.jpg  apple_56.jpg   banana_33.jpg  banana_7.jpg   orange_33.jpg\n",
      "apple_11.xml  apple_56.xml   banana_33.xml  banana_7.xml   orange_33.xml\n",
      "apple_12.jpg  apple_57.jpg   banana_34.jpg  banana_8.jpg   orange_34.jpg\n",
      "apple_12.xml  apple_57.xml   banana_34.xml  banana_8.xml   orange_34.xml\n",
      "apple_13.jpg  apple_58.jpg   banana_35.jpg  banana_9.jpg   orange_35.jpg\n",
      "apple_13.xml  apple_58.xml   banana_35.xml  banana_9.xml   orange_35.xml\n",
      "apple_14.jpg  apple_59.jpg   banana_36.jpg  mixed_10.jpg   orange_36.jpg\n",
      "apple_14.xml  apple_59.xml   banana_36.xml  mixed_10.xml   orange_36.xml\n",
      "apple_15.jpg  apple_5.jpg    banana_37.jpg  mixed_11.jpg   orange_37.jpg\n",
      "apple_15.xml  apple_5.xml    banana_37.xml  mixed_11.xml   orange_37.xml\n",
      "apple_16.jpg  apple_60.jpg   banana_38.jpg  mixed_12.jpg   orange_38.jpg\n",
      "apple_16.xml  apple_60.xml   banana_38.xml  mixed_12.xml   orange_38.xml\n",
      "apple_17.jpg  apple_61.jpg   banana_39.jpg  mixed_13.jpg   orange_3.jpg\n",
      "apple_17.xml  apple_61.xml   banana_39.xml  mixed_13.xml   orange_3.xml\n",
      "apple_18.jpg  apple_62.jpg   banana_3.jpg   mixed_14.jpg   orange_40.jpg\n",
      "apple_18.xml  apple_62.xml   banana_3.xml   mixed_14.xml   orange_40.xml\n",
      "apple_19.jpg  apple_63.jpg   banana_40.jpg  mixed_15.jpg   orange_41.jpg\n",
      "apple_19.xml  apple_63.xml   banana_40.xml  mixed_15.xml   orange_41.xml\n",
      "apple_1.jpg   apple_64.jpg   banana_41.jpg  mixed_16.jpg   orange_42.jpg\n",
      "apple_1.xml   apple_64.xml   banana_41.xml  mixed_16.xml   orange_42.xml\n",
      "apple_20.jpg  apple_65.jpg   banana_42.jpg  mixed_17.jpg   orange_43.jpg\n",
      "apple_20.xml  apple_65.xml   banana_42.xml  mixed_17.xml   orange_43.xml\n",
      "apple_21.jpg  apple_66.jpg   banana_43.jpg  mixed_18.jpg   orange_44.jpg\n",
      "apple_21.xml  apple_66.xml   banana_43.xml  mixed_18.xml   orange_44.xml\n",
      "apple_22.jpg  apple_67.jpg   banana_44.jpg  mixed_19.jpg   orange_46.jpg\n",
      "apple_22.xml  apple_67.xml   banana_44.xml  mixed_19.xml   orange_46.xml\n",
      "apple_23.jpg  apple_68.jpg   banana_45.jpg  mixed_1.jpg    orange_47.jpg\n",
      "apple_23.xml  apple_68.xml   banana_45.xml  mixed_1.xml    orange_47.xml\n",
      "apple_24.jpg  apple_69.jpg   banana_46.jpg  mixed_20.jpg   orange_48.jpg\n",
      "apple_24.xml  apple_69.xml   banana_46.xml  mixed_20.xml   orange_48.xml\n",
      "apple_25.jpg  apple_6.jpg    banana_47.jpg  mixed_2.jpg    orange_49.jpg\n",
      "apple_25.xml  apple_6.xml    banana_47.xml  mixed_2.xml    orange_49.xml\n",
      "apple_26.jpg  apple_70.jpg   banana_48.jpg  mixed_3.jpg    orange_4.jpg\n",
      "apple_26.xml  apple_70.xml   banana_48.xml  mixed_3.xml    orange_4.xml\n",
      "apple_27.jpg  apple_71.jpg   banana_49.jpg  mixed_4.jpg    orange_50.jpg\n",
      "apple_27.xml  apple_71.xml   banana_49.xml  mixed_4.xml    orange_50.xml\n",
      "apple_28.jpg  apple_72.jpg   banana_4.jpg   mixed_5.jpg    orange_51.jpg\n",
      "apple_28.xml  apple_72.xml   banana_4.xml   mixed_5.xml    orange_51.xml\n",
      "apple_29.jpg  apple_73.jpg   banana_50.jpg  mixed_6.jpg    orange_52.jpg\n",
      "apple_29.xml  apple_73.xml   banana_50.xml  mixed_6.xml    orange_52.xml\n",
      "apple_2.jpg   apple_74.jpg   banana_51.jpg  mixed_7.jpg    orange_53.jpg\n",
      "apple_2.xml   apple_74.xml   banana_51.xml  mixed_7.xml    orange_53.xml\n",
      "apple_30.jpg  apple_75.jpg   banana_52.jpg  mixed_8.jpg    orange_54.jpg\n",
      "apple_30.xml  apple_75.xml   banana_52.xml  mixed_8.xml    orange_54.xml\n",
      "apple_31.jpg  apple_76.jpg   banana_53.jpg  mixed_9.jpg    orange_55.jpg\n",
      "apple_31.xml  apple_76.xml   banana_53.xml  mixed_9.xml    orange_55.xml\n",
      "apple_32.jpg  apple_7.jpg    banana_54.jpg  orange_10.jpg  orange_56.jpg\n",
      "apple_32.xml  apple_7.xml    banana_54.xml  orange_10.xml  orange_56.xml\n",
      "apple_33.jpg  apple_8.jpg    banana_55.jpg  orange_11.jpg  orange_57.jpg\n",
      "apple_33.xml  apple_8.xml    banana_55.xml  orange_11.xml  orange_57.xml\n",
      "apple_35.jpg  apple_9.jpg    banana_56.jpg  orange_12.jpg  orange_58.jpg\n",
      "apple_35.xml  apple_9.xml    banana_56.xml  orange_12.xml  orange_58.xml\n",
      "apple_36.jpg  banana_10.jpg  banana_57.jpg  orange_13.jpg  orange_59.jpg\n",
      "apple_36.xml  banana_10.xml  banana_57.xml  orange_13.xml  orange_59.xml\n",
      "apple_37.jpg  banana_11.jpg  banana_58.jpg  orange_14.jpg  orange_5.jpg\n",
      "apple_37.xml  banana_11.xml  banana_58.xml  orange_14.xml  orange_5.xml\n",
      "apple_38.jpg  banana_12.jpg  banana_59.jpg  orange_15.jpg  orange_60.jpg\n",
      "apple_38.xml  banana_12.xml  banana_59.xml  orange_15.xml  orange_60.xml\n",
      "apple_39.jpg  banana_13.jpg  banana_5.jpg   orange_16.jpg  orange_61.jpg\n",
      "apple_39.xml  banana_13.xml  banana_5.xml   orange_16.xml  orange_61.xml\n",
      "apple_3.jpg   banana_14.jpg  banana_60.jpg  orange_17.jpg  orange_62.jpg\n",
      "apple_3.xml   banana_14.xml  banana_60.xml  orange_17.xml  orange_62.xml\n",
      "apple_40.jpg  banana_16.jpg  banana_61.jpg  orange_18.jpg  orange_63.jpg\n",
      "apple_40.xml  banana_16.xml  banana_61.xml  orange_18.xml  orange_63.xml\n",
      "apple_41.jpg  banana_17.jpg  banana_62.jpg  orange_19.jpg  orange_64.jpg\n",
      "apple_41.xml  banana_17.xml  banana_62.xml  orange_19.xml  orange_64.xml\n",
      "apple_42.jpg  banana_1.jpg   banana_63.jpg  orange_1.jpg   orange_67.jpg\n",
      "apple_42.xml  banana_1.xml   banana_63.xml  orange_1.xml   orange_67.xml\n",
      "apple_43.jpg  banana_20.jpg  banana_64.jpg  orange_20.jpg  orange_68.jpg\n",
      "apple_43.xml  banana_20.xml  banana_64.xml  orange_20.xml  orange_68.xml\n",
      "apple_44.jpg  banana_21.jpg  banana_65.jpg  orange_21.jpg  orange_69.jpg\n",
      "apple_44.xml  banana_21.xml  banana_65.xml  orange_21.xml  orange_69.xml\n",
      "apple_45.jpg  banana_22.jpg  banana_66.jpg  orange_22.jpg  orange_6.jpg\n",
      "apple_45.xml  banana_22.xml  banana_66.xml  orange_22.xml  orange_6.xml\n",
      "apple_46.jpg  banana_23.jpg  banana_67.jpg  orange_23.jpg  orange_70.jpg\n",
      "apple_46.xml  banana_23.xml  banana_67.xml  orange_23.xml  orange_70.xml\n",
      "apple_47.jpg  banana_24.jpg  banana_68.jpg  orange_24.jpg  orange_71.jpg\n",
      "apple_47.xml  banana_24.xml  banana_68.xml  orange_24.xml  orange_71.xml\n",
      "apple_48.jpg  banana_25.jpg  banana_69.jpg  orange_25.jpg  orange_72.jpg\n",
      "apple_48.xml  banana_25.xml  banana_69.xml  orange_25.xml  orange_72.xml\n",
      "apple_49.jpg  banana_26.jpg  banana_6.jpg   orange_26.jpg  orange_73.jpg\n",
      "apple_49.xml  banana_26.xml  banana_6.xml   orange_26.xml  orange_73.xml\n",
      "apple_4.jpg   banana_27.jpg  banana_70.jpg  orange_27.jpg  orange_74.jpg\n",
      "apple_4.xml   banana_27.xml  banana_70.xml  orange_27.xml  orange_74.xml\n",
      "apple_50.jpg  banana_28.jpg  banana_71.jpg  orange_28.jpg  orange_75.jpg\n",
      "apple_50.xml  banana_28.xml  banana_71.xml  orange_28.xml  orange_75.xml\n",
      "apple_51.jpg  banana_29.jpg  banana_72.jpg  orange_29.jpg  orange_76.jpg\n",
      "apple_51.xml  banana_29.xml  banana_72.xml  orange_29.xml  orange_76.xml\n",
      "apple_52.jpg  banana_2.jpg   banana_73.jpg  orange_2.jpg   orange_7.jpg\n",
      "apple_52.xml  banana_2.xml   banana_73.xml  orange_2.xml   orange_7.xml\n",
      "apple_53.jpg  banana_30.jpg  banana_74.jpg  orange_30.jpg  orange_8.jpg\n",
      "apple_53.xml  banana_30.xml  banana_74.xml  orange_30.xml  orange_8.xml\n",
      "apple_54.jpg  banana_31.jpg  banana_75.jpg  orange_31.jpg  orange_9.jpg\n",
      "apple_54.xml  banana_31.xml  banana_75.xml  orange_31.xml  orange_9.xml\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI8__uNS8-ns"
   },
   "source": [
    "# Install Tensorflow Object Detection API\n",
    "\n",
    "Clone TF models which contains the Object Detection API; also install the required dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ecpHEnka8Kix",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c00a900d-b178-4bc6-e75a-5a056101f7b8"
   },
   "source": [
    "# %%capture\n",
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "%cd /content/models/\n",
    "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
    "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "!pip install -q pycocotools\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "!python object_detection/builders/model_builder_test.py"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'models' already exists and is not an empty directory.\n",
      "/content/models\n",
      "HEAD is now at 58d19c67 Internal change\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Reading package lists... Done\n",
      "/content/models/research\n",
      "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-k7uGThXlny"
   },
   "source": [
    "## Prepare `tfrecord` files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ezGDABRXXhPP"
   },
   "source": [
    "%%capture\n",
    "%cd {repo_dir_path}\n",
    "\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Set the paths\n",
    "test_record_fname = '/content/object_detection_demo_flow/data/annotations/test.record'\n",
    "train_record_fname = '/content/object_detection_demo_flow/data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/content/object_detection_demo_flow/data/annotations/label_map.pbtxt'"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCNYAaC7w6N8"
   },
   "source": [
    "## Download the Mobilenet SSD v2 Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "orDCj6ihgUMR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "976488b1-8a0b-47e2-b5de-ec014126f834"
   },
   "source": [
    "%cd /content/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/content/models/research/pretrained_model'\n",
    "\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)\n",
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/models/research\n",
      "/content/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
      "drwxr-xr-x 63 root   root  4.0K Jun  2 09:47 ..\n",
      "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
      "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
      "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UHnxlfRznPP3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "e020e004-597a-4367-bee2-7d6611a3c2fe"
   },
   "source": [
    "#TF pretrained model checkpoint\n",
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvwtHlLOeRJD"
   },
   "source": [
    "## Configuring a Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dIhw7IdpLuiU"
   },
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FRofNAq5GDXY",
    "outputId": "5a41a872-1f4f-4fe2-bd42-a5275f07417c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "parent = Path(label_map_pbtxt_fname).parent\n",
    "!ls {parent}"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "label_map.pbtxt  test_labels.csv  test.record  train_labels.csv  train.record\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YjtCbLF2i0wI"
   },
   "source": [
    "import re\n",
    "iou_threshold = 0.50\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('iou_threshold: [0-9].[0-9]+',\n",
    "               'iou_threshold: {}'.format(iou_threshold), s)\n",
    "    \n",
    "    f.write(s)"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GH0MEEanocn6"
   },
   "source": [
    "# #Have a look at the config file with various settings\n",
    "# !cat {pipeline_fname}"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDddx2rPfex9"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS6W4ZEEWBgM"
   },
   "source": [
    "##[Optional] The cell below adds Tensorboard visualization to the training process.\n",
    "Will open in new tab."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f11w0uO3jFCB"
   },
   "source": [
    "#After running this cell click on the link in the output cell to open tensorboard\n",
    "#Tensoarboard will show you graphically different training parameters as the model is training\n",
    "#when training finishes after the set number of steps, tensorboard can be used to see a nice summary of the training process\n",
    "#Visuals will load in Tensorboard after the model has gone through a few hundred steps\n",
    "\n",
    "model_dir = 'training/'\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOyWAHNywiL4"
   },
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CjDHjhKQofT5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9142ec35-3bc9-4195-be4a-d86212735305"
   },
   "source": [
    "model_dir = 'training/'\n",
    "# Optionally remove content in output model directory for a fresh start.\n",
    "# !rm -rf {model_dir}\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "!python /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0602 09:48:19.128261 139780563216256 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 50\n",
      "I0602 09:48:19.128546 139780563216256 config_util.py:552] Maybe overwriting train_steps: 50\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0602 09:48:19.128694 139780563216256 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0602 09:48:19.128833 139780563216256 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0602 09:48:19.128976 139780563216256 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "I0602 09:48:19.129130 139780563216256 config_util.py:552] Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "I0602 09:48:19.129268 139780563216256 config_util.py:562] Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0602 09:48:19.129573 139780563216256 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "I0602 09:48:19.129726 139780563216256 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f20c670f0d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0602 09:48:19.130254 139780563216256 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f20c670f0d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f20c61d4290>) includes params argument, but params are not passed to Estimator.\n",
      "W0602 09:48:19.130530 139780563216256 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f20c61d4290>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0602 09:48:19.130960 139780563216256 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0602 09:48:19.131207 139780563216256 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0602 09:48:19.131536 139780563216256 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0602 09:48:19.146752 139780563216256 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0602 09:48:19.174782 139780563216256 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0602 09:48:19.180596 139780563216256 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0602 09:48:19.202269 139780563216256 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f20c61f8650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "W0602 09:48:19.235775 139780563216256 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f20c61f8650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f20c61d4710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "W0602 09:48:19.475579 139780563216256 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f20c61d4710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0602 09:48:19.482558 139780563216256 deprecation.py:323] From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0602 09:48:19.491570 139780563216256 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0602 09:48:19.604907 139780563216256 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0602 09:48:20.516795 139780563216256 deprecation.py:323] From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0602 09:48:21.081335 139780563216256 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0602 09:48:21.656523 139780563216256 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.789742 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.825608 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.860999 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.897658 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.933776 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:48:24.969840 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "W0602 09:48:25.017765 139780563216256 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
      "W0602 09:48:25.017969 139780563216256 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
      "W0602 09:48:25.018176 139780563216256 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
      "W0602 09:48:25.018338 139780563216256 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0602 09:48:33.891429 139780563216256 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0602 09:48:41.464284 139780563216256 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0602 09:48:41.465798 139780563216256 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0602 09:48:46.045215 139780563216256 monitored_session.py:240] Graph was finalized.\n",
      "2021-06-02 09:48:46.057467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-06-02 09:48:46.057800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f7e465d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-02 09:48:46.057843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-02 09:48:46.062335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-02 09:48:46.258183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:46.259071: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f91e9a1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-02 09:48:46.259127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2021-06-02 09:48:46.260579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:46.261333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-02 09:48:46.277118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-02 09:48:46.521709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-02 09:48:46.641922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-02 09:48:46.664473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-02 09:48:46.920939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-02 09:48:46.962167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-02 09:48:47.458307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-02 09:48:47.458532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:47.459377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:47.460076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-02 09:48:47.463819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-02 09:48:47.465440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-02 09:48:47.465475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-02 09:48:47.465492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-02 09:48:47.465994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:47.466902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:48:47.467644: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-02 09:48:47.467701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0602 09:48:58.466773 139780563216256 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0602 09:48:58.933186 139780563216256 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0602 09:49:12.220435 139780563216256 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "2021-06-02 09:49:27.708581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-02 09:49:31.756958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:loss = 5.0811076, step = 0\n",
      "I0602 09:49:35.680533 139780563216256 basic_session_run_hooks.py:262] loss = 5.0811076, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 50 into training/model.ckpt.\n",
      "I0602 09:50:25.517943 139780563216256 basic_session_run_hooks.py:606] Saving checkpoints for 50 into training/model.ckpt.\n",
      "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f20b0087710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "W0602 09:50:27.469154 139780563216256 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f20b0087710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f20bdf399e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "W0602 09:50:27.679934 139780563216256 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f20bdf399e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0602 09:50:28.318253 139780563216256 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.206665 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.243586 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.280134 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.317935 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.354148 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:31.390428 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0602 09:50:32.281659 139780563216256 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0602 09:50:32.524607 139780563216256 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0602 09:50:33.183941 139780563216256 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-06-02T09:50:33Z\n",
      "I0602 09:50:33.204362 139780563216256 evaluation.py:255] Starting evaluation at 2021-06-02T09:50:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0602 09:50:33.718671 139780563216256 monitored_session.py:240] Graph was finalized.\n",
      "2021-06-02 09:50:33.719940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:33.720593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-02 09:50:33.720698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-02 09:50:33.720742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-02 09:50:33.720791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-02 09:50:33.720833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-02 09:50:33.720877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-02 09:50:33.720925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-02 09:50:33.720981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-02 09:50:33.721098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:33.721721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:33.722260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-02 09:50:33.722318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-02 09:50:33.722339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-02 09:50:33.722353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-02 09:50:33.722482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:33.723073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:33.723629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-50\n",
      "I0602 09:50:33.724850 139780563216256 saver.py:1284] Restoring parameters from training/model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0602 09:50:34.680707 139780563216256 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0602 09:50:34.835615 139780563216256 session_manager.py:502] Done running local_init_op.\n",
      "2021-06-02 09:50:36.751035: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "INFO:tensorflow:Performing evaluation on 60 images.\n",
      "I0602 09:50:42.007884 139778385839872 coco_evaluation.py:237] Performing evaluation on 60 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0602 09:50:42.008526 139778385839872 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I0602 09:50:42.017632 139778385839872 coco_tools.py:138] DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.057\n",
      "INFO:tensorflow:Finished evaluation at 2021-06-02-09:50:43\n",
      "I0602 09:50:43.071591 139780563216256 evaluation.py:275] Finished evaluation at 2021-06-02-09:50:43\n",
      "INFO:tensorflow:Saving dict for global step 50: DetectionBoxes_Precision/mAP = 0.0043178643, DetectionBoxes_Precision/mAP (large) = 0.004021681, DetectionBoxes_Precision/mAP (medium) = 0.012871287, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0191429, DetectionBoxes_Precision/mAP@.75IOU = 1.5740843e-05, DetectionBoxes_Recall/AR@1 = 0.016904762, DetectionBoxes_Recall/AR@10 = 0.03876984, DetectionBoxes_Recall/AR@100 = 0.05813492, DetectionBoxes_Recall/AR@100 (large) = 0.057030555, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 4.337233, Loss/localization_loss = 1.7171092, Loss/regularization_loss = 0.24715048, Loss/total_loss = 6.3014927, global_step = 50, learning_rate = 0.004, loss = 6.3014927\n",
      "I0602 09:50:43.071954 139780563216256 estimator.py:2049] Saving dict for global step 50: DetectionBoxes_Precision/mAP = 0.0043178643, DetectionBoxes_Precision/mAP (large) = 0.004021681, DetectionBoxes_Precision/mAP (medium) = 0.012871287, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0191429, DetectionBoxes_Precision/mAP@.75IOU = 1.5740843e-05, DetectionBoxes_Recall/AR@1 = 0.016904762, DetectionBoxes_Recall/AR@10 = 0.03876984, DetectionBoxes_Recall/AR@100 = 0.05813492, DetectionBoxes_Recall/AR@100 (large) = 0.057030555, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 4.337233, Loss/localization_loss = 1.7171092, Loss/regularization_loss = 0.24715048, Loss/total_loss = 6.3014927, global_step = 50, learning_rate = 0.004, loss = 6.3014927\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: training/model.ckpt-50\n",
      "I0602 09:50:44.035641 139780563216256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: training/model.ckpt-50\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "I0602 09:50:44.036652 139780563216256 exporter.py:410] Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0602 09:50:44.362436 139780563216256 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.006376 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.044972 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.081326 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.119338 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.157386 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0602 09:50:47.194126 139780563216256 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0602 09:50:48.123668 139780563216256 estimator.py:1150] Done calling model_fn.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0602 09:50:48.124004 139780563216256 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0602 09:50:48.124803 139780563216256 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0602 09:50:48.124966 139780563216256 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
      "I0602 09:50:48.125122 139780563216256 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "I0602 09:50:48.125260 139780563216256 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "I0602 09:50:48.125390 139780563216256 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "2021-06-02 09:50:48.126019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:48.126653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-02 09:50:48.126741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-02 09:50:48.126784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-02 09:50:48.126831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-02 09:50:48.126886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-02 09:50:48.126928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-02 09:50:48.126967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-02 09:50:48.127008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-02 09:50:48.127119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:48.127720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:48.128263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-02 09:50:48.128315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-02 09:50:48.128339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-02 09:50:48.128354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-02 09:50:48.128476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:48.129072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-02 09:50:48.129615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-50\n",
      "I0602 09:50:48.132769 139780563216256 saver.py:1284] Restoring parameters from training/model.ckpt-50\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0602 09:50:48.612068 139780563216256 builder_impl.py:665] Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0602 09:50:48.612341 139780563216256 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1622627444'/saved_model.pb\n",
      "I0602 09:50:49.445667 139780563216256 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1622627444'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 3.7304785.\n",
      "I0602 09:50:49.910458 139780563216256 estimator.py:371] Loss for final step: 3.7304785.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KP-tUdtnRybs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b2c7f399-4aba-4aa0-b0f5-810293041731"
   },
   "source": [
    "#model dir check for the trained model\n",
    "!ls {model_dir}"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t\t     model.ckpt-0.index\n",
      "eval_0\t\t\t\t\t     model.ckpt-0.meta\n",
      "events.out.tfevents.1622627323.2b4ac043dc41  model.ckpt-50.data-00000-of-00001\n",
      "export\t\t\t\t\t     model.ckpt-50.index\n",
      "graph.pbtxt\t\t\t\t     model.ckpt-50.meta\n",
      "model.ckpt-0.data-00000-of-00001\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmSESMetj1sa"
   },
   "source": [
    "## Export a Trained Inference Graph\n",
    "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zZJ_AF5MD3hZ"
   },
   "source": [
    "#clean output_directory if necessary to start fresh:\n",
    "\n",
    "# !rm -rf /content/object_detection_demo/fine_tuned_model/ \n",
    "# os.makedirs('/content/object_detection_demo_flow/fine_tuned_model/', exist_ok=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DHoP90pUyKSq"
   },
   "source": [
    "%%capture\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "# output_directory = '/content/gdrive/My\\ Drive/data/'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "usgBZvkz0nqD",
    "outputId": "081b6675-23e4-412b-f9ca-75f6bab8466b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#export directory check\n",
    "!ls {output_directory}"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
      "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
      "model.ckpt.data-00000-of-00001\tpipeline.config\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CnDo1lonKgFr"
   },
   "source": [
    "import os\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n",
    "# !ls -alh {pb_fname}"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz1gX19GlVW7"
   },
   "source": [
    "## Running Inference: Checking what the trained model can detect\n",
    "Test with images in repository `object_detection_demo_flow/data/images/final test` directory."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pzj9A4e5mj5l",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d20c52e8-dc65-42e0-eb6b-3e2cee97f841"
   },
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/images/final_test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "['/content/object_detection_demo_flow/data/images/final_test/banana_82.jpg', '/content/object_detection_demo_flow/data/images/final_test/mixed_24.jpg', '/content/object_detection_demo_flow/data/images/final_test/banana_77.jpg', '/content/object_detection_demo_flow/data/images/final_test/apple_91.jpg', '/content/object_detection_demo_flow/data/images/final_test/banana_78.jpg', '/content/object_detection_demo_flow/data/images/final_test/apple_94.jpg', '/content/object_detection_demo_flow/data/images/final_test/banana_81.jpg', '/content/object_detection_demo_flow/data/images/final_test/banana_80.jpg', '/content/object_detection_demo_flow/data/images/final_test/orange_77.jpg', '/content/object_detection_demo_flow/data/images/final_test/mixed_21.jpg', '/content/object_detection_demo_flow/data/images/final_test/apple_93.jpg', '/content/object_detection_demo_flow/data/images/final_test/apple_90.jpg', '/content/object_detection_demo_flow/data/images/final_test/mixed_23.jpg', '/content/object_detection_demo_flow/data/images/final_test/orange_81.jpg', '/content/object_detection_demo_flow/data/images/final_test/orange_82.jpg', '/content/object_detection_demo_flow/data/images/final_test/mixed_22.jpg', '/content/object_detection_demo_flow/data/images/final_test/banana_79.jpg']\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CG5YUMdg1Po7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "80dcebc3-21ba-4423-983f-f375ad7f911e"
   },
   "source": [
    "%cd /content/models/research/object_detection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    print(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)\n",
    "    plt.show()"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/models/research/object_detection\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_82.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/mixed_24.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_77.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/apple_91.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_78.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/apple_94.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_81.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_80.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/orange_77.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/mixed_21.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/apple_93.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/apple_90.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/mixed_23.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/orange_81.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/orange_82.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/mixed_22.jpg\n",
      "/content/object_detection_demo_flow/data/images/final_test/banana_79.jpg\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PlfZAR1OCK2"
   },
   "source": [
    "# Convert TF model to OpenVINO 21.03 Intermediate Representation (IR)\n",
    " This can be used to run inference on OpenVINO.\n",
    "# In order to run the model on DepthAI modules, we then compile the IR obtained above to a .blob (via a server we set up just for that) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qucQJwsWhL3"
   },
   "source": [
    "## First, we install Open Vino 21.03\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0BxCxkQ6NkcF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b83e9daf-87a8-4e5f-f5e9-d8f2be830cd8"
   },
   "source": [
    "%cd ../.."
   ],
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/models\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5py5tfxS6VaA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9d0d5da2-79c4-4c30-d92f-565999d7f24a"
   },
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "## install tools. Open Vino takes some time to download - it's ~400MB\n",
    "!sudo apt-get install -y pciutils cpio\n",
    "!sudo apt autoremove\n",
    "\n",
    "## downnload installation files\n",
    "url = \"https://registrationcenter-download.intel.com/akdlm/irc_nas/17662/l_openvino_toolkit_p_2021.3.394.tgz\"\n",
    "!wget {url}\n",
    "\n",
    "## Get the name of the tgz\n",
    "parsed = urlparse(url)\n",
    "openvino_tgz = os.path.basename(parsed.path)\n",
    "openvino_folder = os.path.splitext(openvino_tgz)[0]\n",
    "\n",
    "## Extract & install openvino\n",
    "!tar xf {openvino_tgz}\n",
    "%cd {openvino_folder}\n",
    "!./install_openvino_dependencies.sh && \\\n",
    "    sed -i 's/decline/accept/g' silent.cfg && \\\n",
    "    ./install.sh --silent silent.cfg"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  libpci3\n",
      "Suggested packages:\n",
      "  libarchive1\n",
      "The following NEW packages will be installed:\n",
      "  cpio libpci3 pciutils\n",
      "0 upgraded, 3 newly installed, 0 to remove and 97 not upgraded.\n",
      "Need to get 368 kB of archives.\n",
      "After this operation, 1,786 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 cpio amd64 2.12+dfsg-6ubuntu0.18.04.1 [86.2 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpci3 amd64 1:3.5.2-1ubuntu1.1 [24.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 pciutils amd64 1:3.5.2-1ubuntu1.1 [257 kB]\n",
      "Fetched 368 kB in 2s (201 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package cpio.\n",
      "(Reading database ... 161091 files and directories currently installed.)\n",
      "Preparing to unpack .../cpio_2.12+dfsg-6ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libpci3:amd64.\n",
      "Preparing to unpack .../libpci3_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
      "Selecting previously unselected package pciutils.\n",
      "Preparing to unpack .../pciutils_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking pciutils (1:3.5.2-1ubuntu1.1) ...\n",
      "Setting up cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
      "update-alternatives: using /bin/mt-gnu to provide /bin/mt (mt) in auto mode\n",
      "Setting up libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
      "Setting up pciutils (1:3.5.2-1ubuntu1.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages will be REMOVED:\n",
      "  libnvidia-common-460\n",
      "0 upgraded, 0 newly installed, 1 to remove and 96 not upgraded.\n",
      "After this operation, 35.8 kB disk space will be freed.\n",
      "(Reading database ... 161122 files and directories currently installed.)\n",
      "Removing libnvidia-common-460 (460.73.01-0ubuntu1) ...\n",
      "--2021-06-02 09:54:25--  https://registrationcenter-download.intel.com/akdlm/irc_nas/17662/l_openvino_toolkit_p_2021.3.394.tgz\n",
      "Resolving registrationcenter-download.intel.com (registrationcenter-download.intel.com)... 23.199.34.32, 104.116.243.115\n",
      "Connecting to registrationcenter-download.intel.com (registrationcenter-download.intel.com)|23.199.34.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 551176145 (526M) [application/octet-stream]\n",
      "Saving to: l_openvino_toolkit_p_2021.3.394.tgz\n",
      "\n",
      "l_openvino_toolkit_ 100%[===================>] 525.64M  50.6MB/s    in 10s     \n",
      "\n",
      "2021-06-02 09:54:35 (51.4 MB/s) - l_openvino_toolkit_p_2021.3.394.tgz saved [551176145/551176145]\n",
      "\n",
      "/content/models/l_openvino_toolkit_p_2021.3.394\n",
      "Detected OS: ubuntu18.04\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Note, selecting 'libgl1-mesa-dev' instead of 'libgl-dev'\n",
      "libusb-1.0-0 is already the newest version (2:1.0.21-2).\n",
      "libusb-1.0-0 set to manually installed.\n",
      "make is already the newest version (4.1-9.1ubuntu1).\n",
      "make set to manually installed.\n",
      "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
      "cpio is already the newest version (2.12+dfsg-6ubuntu0.18.04.1).\n",
      "curl is already the newest version (7.58.0-2ubuntu3.13).\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "g++ set to manually installed.\n",
      "gcc is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "gcc set to manually installed.\n",
      "libc6-dev is already the newest version (2.27-3ubuntu1.4).\n",
      "libc6-dev set to manually installed.\n",
      "libgl1 is already the newest version (1.0.0-2ubuntu2.3).\n",
      "libgl1-mesa-dev is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
      "libgl1-mesa-dev set to manually installed.\n",
      "libglib2.0-dev is already the newest version (2.56.4-0ubuntu0.18.04.8).\n",
      "libglib2.0-dev set to manually installed.\n",
      "libgtk-3-0 is already the newest version (3.22.30-1ubuntu4).\n",
      "libgtk-3-0 set to manually installed.\n",
      "libtinfo5 is already the newest version (6.1-1ubuntu1.18.04).\n",
      "python3 is already the newest version (3.6.7-1~18.04).\n",
      "python3 set to manually installed.\n",
      "python3-dev is already the newest version (3.6.7-1~18.04).\n",
      "python3-dev set to manually installed.\n",
      "python3-gi is already the newest version (3.26.1-2ubuntu1).\n",
      "python3-gi set to manually installed.\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libavcodec57 is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libavcodec57 set to manually installed.\n",
      "libavformat57 is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libavformat57 set to manually installed.\n",
      "libavresample3 is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libavresample3 set to manually installed.\n",
      "libavutil55 is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libavutil55 set to manually installed.\n",
      "libswscale4 is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "libswscale4 set to manually installed.\n",
      "The following additional packages will be installed:\n",
      "  liba52-0.7.4 libaa1 libcap2-bin libcdparanoia0 libdca0 libde265-0 libdv4\n",
      "  libdvdnav4 libdvdread4 libfaad2 libgpm2 libgssdp-1.0-3 libgstreamer-gl1.0-0\n",
      "  libgstreamer-plugins-bad1.0-0 libgstreamer-plugins-base1.0-0\n",
      "  libgstreamer-plugins-good1.0-0 libgupnp-1.0-4 libgupnp-igd-1.0-4 libhogweed4\n",
      "  libkate1 liblilv-0-0 libmjpegutils-2.1-0 libmms0 libmodplug1 libmpcdec6\n",
      "  libmpeg2-4 libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10 libofa0\n",
      "  libopencore-amrnb0 libopencore-amrwb0 liborc-0.4-0 libsbc1 libserd-0-0\n",
      "  libshout3 libsidplay1v5 libsigsegv2 libsord-0-0 libsoundtouch1 libspandsp2\n",
      "  libsratom-0-0 libsrtp2-1 libtag1v5 libtag1v5-vanilla libv4l-0 libv4lconvert0\n",
      "  libva-wayland2 libvisual-0.4-0 libvo-aacenc0 libvo-amrwbenc0 libvulkan1\n",
      "  libwebrtc-audio-processing1 libwildmidi-config libwildmidi2 libzbar0 m4\n",
      "  python-pip-whl python3-pkg-resources python3.6-venv\n",
      "Suggested packages:\n",
      "  bison flex-doc alsa-utils frei0r-plugins gvfs gstreamer1.0-vaapi-doc\n",
      "  libdv-bin oss-compat libdvdcss2 fluidr3mono-gm-soundfont\n",
      "  | timgm6mb-soundfont | fluid-soundfont-gm gpm libvisual-0.4-plugins serdi\n",
      "  sidplay-base sordi m4-doc python-setuptools-doc\n",
      "Recommended packages:\n",
      "  libfl-dev gstreamer1.0-x libpam-cap gstreamer1.0-gl mesa-vulkan-drivers\n",
      "  | vulkan-icd freepats python3-wheel\n",
      "The following NEW packages will be installed:\n",
      "  flex gstreamer1.0-alsa gstreamer1.0-plugins-bad gstreamer1.0-plugins-base\n",
      "  gstreamer1.0-plugins-good gstreamer1.0-plugins-ugly gstreamer1.0-tools\n",
      "  gstreamer1.0-vaapi liba52-0.7.4 libaa1 libcap2-bin libcdparanoia0 libdca0\n",
      "  libde265-0 libdv4 libdvdnav4 libdvdread4 libfaac0 libfaad2 libfluidsynth1\n",
      "  libgpm2 libgssdp-1.0-3 libgstreamer-gl1.0-0 libgstreamer-plugins-bad1.0-0\n",
      "  libgstreamer-plugins-base1.0-0 libgstreamer-plugins-good1.0-0\n",
      "  libgstreamer1.0-0 libgupnp-1.0-4 libgupnp-igd-1.0-4 libkate1 liblilv-0-0\n",
      "  libmjpegutils-2.1-0 libmms0 libmodplug1 libmpcdec6 libmpeg2-4\n",
      "  libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10 libofa0 libopencore-amrnb0\n",
      "  libopencore-amrwb0 liborc-0.4-0 libsbc1 libserd-0-0 libshout3 libsidplay1v5\n",
      "  libsigsegv2 libsord-0-0 libsoundtouch1 libspandsp2 libsratom-0-0 libsrtp2-1\n",
      "  libtag-extras1 libtag1v5 libtag1v5-vanilla libv4l-0 libv4lconvert0\n",
      "  libva-wayland2 libvisual-0.4-0 libvo-aacenc0 libvo-amrwbenc0 libvulkan1\n",
      "  libwebrtc-audio-processing1 libwildmidi-config libwildmidi2 libzbar0 m4\n",
      "  python-pip-whl python3-pip python3-pkg-resources python3-setuptools\n",
      "  python3-venv python3.6-venv vainfo\n",
      "The following packages will be upgraded:\n",
      "  libhogweed4 libnettle6\n",
      "2 upgraded, 75 newly installed, 0 to remove and 94 not upgraded.\n",
      "Need to get 13.3 MB of archives.\n",
      "After this operation, 43.3 MB of additional disk space will be used.\n",
      "Get:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 libvulkan1 amd64 1.1.126.0-2~gpu18.04.1 [101 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 flex amd64 2.6.4-6 [316 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libvo-aacenc0 amd64 0.1.3-1 [71.0 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libvo-amrwbenc0 amd64 0.1.3-1 [66.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnettle6 amd64 3.4-1ubuntu0.1 [110 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libhogweed4 amd64 3.4-1ubuntu0.1 [137 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcap2-bin amd64 1:2.25-1.2 [20.6 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgstreamer1.0-0 amd64 1.14.5-0ubuntu1~18.04.2 [865 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 liborc-0.4-0 amd64 1:0.4.28-1 [137 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgstreamer-plugins-base1.0-0 amd64 1.14.5-0ubuntu1~18.04.3 [689 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gstreamer1.0-alsa amd64 1.14.5-0ubuntu1~18.04.3 [35.5 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdparanoia0 amd64 3.10.2+debian-13 [46.7 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvisual-0.4-0 amd64 0.4.0-11 [99.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gstreamer1.0-plugins-base amd64 1.14.5-0ubuntu1~18.04.3 [586 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgpm2 amd64 1.20.7-5 [15.1 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaa1 amd64 1.4p5-44build2 [47.2 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdv4 amd64 1.0.0-11 [57.8 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgstreamer-plugins-good1.0-0 amd64 1.14.5-0ubuntu1~18.04.2 [62.6 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libshout3 amd64 2.4.1-2build1 [43.1 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtag1v5-vanilla amd64 1.11.1+dfsg.1-0.2build2 [265 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtag1v5 amd64 1.11.1+dfsg.1-0.2build2 [10.9 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libv4lconvert0 amd64 1.14.2-1 [76.1 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libv4l-0 amd64 1.14.2-1 [41.7 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gstreamer1.0-plugins-good amd64 1.14.5-0ubuntu1~18.04.2 [1,691 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liba52-0.7.4 amd64 0.7.4-19 [35.2 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdvdread4 amd64 6.0.0-1 [50.6 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpeg2-4 amd64 0.5.1-8 [57.5 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsidplay1v5 amd64 1.36.59-11 [63.2 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gstreamer1.0-plugins-ugly amd64 1.14.5-0ubuntu1~18.04.1 [237 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gstreamer1.0-tools amd64 1.14.5-0ubuntu1~18.04.2 [40.5 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgstreamer-gl1.0-0 amd64 1.14.5-0ubuntu1~18.04.3 [147 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libgstreamer-plugins-bad1.0-0 amd64 1.14.5-0ubuntu1~18.04.1 [322 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva-wayland2 amd64 2.1.0-3 [8,756 B]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gstreamer1.0-vaapi amd64 1.14.5-0ubuntu1~ubuntu18.04.1 [310 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libde265-0 amd64 1.0.2-2build1 [234 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdvdnav4 amd64 6.0.0-1 [38.0 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libfaac0 amd64 1.29.7.7-1 [44.4 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfaad2 amd64 2.8.8-1 [154 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth1 amd64 1.1.9-1 [137 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgssdp-1.0-3 amd64 1.0.2-2 [23.0 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgupnp-1.0-4 amd64 1.0.2-2 [59.7 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgupnp-igd-1.0-4 amd64 0.2.5-1 [14.9 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libkate1 amd64 0.4.1-7build1 [38.1 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libserd-0-0 amd64 0.28.0~dfsg0-1 [37.0 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsord-0-0 amd64 0.16.0~dfsg0-1 [20.2 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsratom-0-0 amd64 0.6.0~dfsg0-1 [15.8 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblilv-0-0 amd64 0.24.2~dfsg0-1 [38.0 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmjpegutils-2.1-0 amd64 1:2.1.0+debian-5 [24.6 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmms0 amd64 0.6.4-2 [27.4 kB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmodplug1 amd64 1:0.8.9.0-1 [150 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpcdec6 amd64 2:0.1~r495-1 [32.3 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpeg2encpp-2.1-0 amd64 1:2.1.0+debian-5 [67.6 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmplex2-2.1-0 amd64 1:2.1.0+debian-5 [43.7 kB]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libnice10 amd64 0.1.14-1 [126 kB]\n",
      "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libofa0 amd64 0.9.3-15 [49.1 kB]\n",
      "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsoundtouch1 amd64 1.9.2-3 [39.6 kB]\n",
      "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspandsp2 amd64 0.0.6+dfsg-0.1 [273 kB]\n",
      "Get:62 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsrtp2-1 amd64 2.1.0-1 [57.4 kB]\n",
      "Get:63 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtag-extras1 amd64 1.0.1-3.1 [18.6 kB]\n",
      "Get:64 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebrtc-audio-processing1 amd64 0.3-1 [260 kB]\n",
      "Get:65 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libwildmidi-config all 0.4.2-1 [7,212 B]\n",
      "Get:66 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libwildmidi2 amd64 0.4.2-1 [55.8 kB]\n",
      "Get:67 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzbar0 amd64 0.10+doc-10.1build2 [75.7 kB]\n",
      "Get:68 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1,653 kB]\n",
      "Get:69 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.4 [114 kB]\n",
      "Get:70 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
      "Get:71 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
      "Get:72 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.4 [6,188 B]\n",
      "Get:73 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
      "Get:74 http://archive.ubuntu.com/ubuntu bionic/universe amd64 vainfo amd64 2.1.0+ds1-1 [9,884 B]\n",
      "Get:75 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdca0 amd64 0.0.5-10 [100.0 kB]\n",
      "Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsbc1 amd64 1.3-2 [33.1 kB]\n",
      "Get:77 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gstreamer1.0-plugins-bad amd64 1.14.5-0ubuntu1~18.04.1 [1,627 kB]\n",
      "Fetched 13.3 MB in 5s (2,473 kB/s)\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package libsigsegv2:amd64.\n",
      "(Reading database ... 161117 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libsigsegv2_2.12-1_amd64.deb ...\n",
      "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
      "Selecting previously unselected package m4.\n",
      "Preparing to unpack .../1-m4_1.4.18-1_amd64.deb ...\n",
      "Unpacking m4 (1.4.18-1) ...\n",
      "Selecting previously unselected package flex.\n",
      "Preparing to unpack .../2-flex_2.6.4-6_amd64.deb ...\n",
      "Unpacking flex (2.6.4-6) ...\n",
      "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
      "Preparing to unpack .../3-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
      "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
      "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
      "Preparing to unpack .../4-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
      "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
      "Selecting previously unselected package libvo-aacenc0:amd64.\n",
      "Preparing to unpack .../5-libvo-aacenc0_0.1.3-1_amd64.deb ...\n",
      "Unpacking libvo-aacenc0:amd64 (0.1.3-1) ...\n",
      "Selecting previously unselected package libvo-amrwbenc0:amd64.\n",
      "Preparing to unpack .../6-libvo-amrwbenc0_0.1.3-1_amd64.deb ...\n",
      "Unpacking libvo-amrwbenc0:amd64 (0.1.3-1) ...\n",
      "Preparing to unpack .../7-libnettle6_3.4-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libnettle6:amd64 (3.4-1ubuntu0.1) over (3.4-1) ...\n",
      "Setting up libnettle6:amd64 (3.4-1ubuntu0.1) ...\n",
      "(Reading database ... 161277 files and directories currently installed.)\n",
      "Preparing to unpack .../libhogweed4_3.4-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libhogweed4:amd64 (3.4-1ubuntu0.1) over (3.4-1) ...\n",
      "Setting up libhogweed4:amd64 (3.4-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libcap2-bin.\n",
      "(Reading database ... 161277 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libcap2-bin_1%3a2.25-1.2_amd64.deb ...\n",
      "Unpacking libcap2-bin (1:2.25-1.2) ...\n",
      "Selecting previously unselected package libgstreamer1.0-0:amd64.\n",
      "Preparing to unpack .../01-libgstreamer1.0-0_1.14.5-0ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking libgstreamer1.0-0:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Selecting previously unselected package liborc-0.4-0:amd64.\n",
      "Preparing to unpack .../02-liborc-0.4-0_1%3a0.4.28-1_amd64.deb ...\n",
      "Unpacking liborc-0.4-0:amd64 (1:0.4.28-1) ...\n",
      "Selecting previously unselected package libgstreamer-plugins-base1.0-0:amd64.\n",
      "Preparing to unpack .../03-libgstreamer-plugins-base1.0-0_1.14.5-0ubuntu1~18.04.3_amd64.deb ...\n",
      "Unpacking libgstreamer-plugins-base1.0-0:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Selecting previously unselected package gstreamer1.0-alsa:amd64.\n",
      "Preparing to unpack .../04-gstreamer1.0-alsa_1.14.5-0ubuntu1~18.04.3_amd64.deb ...\n",
      "Unpacking gstreamer1.0-alsa:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Selecting previously unselected package libcdparanoia0:amd64.\n",
      "Preparing to unpack .../05-libcdparanoia0_3.10.2+debian-13_amd64.deb ...\n",
      "Unpacking libcdparanoia0:amd64 (3.10.2+debian-13) ...\n",
      "Selecting previously unselected package libvisual-0.4-0:amd64.\n",
      "Preparing to unpack .../06-libvisual-0.4-0_0.4.0-11_amd64.deb ...\n",
      "Unpacking libvisual-0.4-0:amd64 (0.4.0-11) ...\n",
      "Selecting previously unselected package gstreamer1.0-plugins-base:amd64.\n",
      "Preparing to unpack .../07-gstreamer1.0-plugins-base_1.14.5-0ubuntu1~18.04.3_amd64.deb ...\n",
      "Unpacking gstreamer1.0-plugins-base:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Selecting previously unselected package libgpm2:amd64.\n",
      "Preparing to unpack .../08-libgpm2_1.20.7-5_amd64.deb ...\n",
      "Unpacking libgpm2:amd64 (1.20.7-5) ...\n",
      "Selecting previously unselected package libaa1:amd64.\n",
      "Preparing to unpack .../09-libaa1_1.4p5-44build2_amd64.deb ...\n",
      "Unpacking libaa1:amd64 (1.4p5-44build2) ...\n",
      "Selecting previously unselected package libdv4:amd64.\n",
      "Preparing to unpack .../10-libdv4_1.0.0-11_amd64.deb ...\n",
      "Unpacking libdv4:amd64 (1.0.0-11) ...\n",
      "Selecting previously unselected package libgstreamer-plugins-good1.0-0:amd64.\n",
      "Preparing to unpack .../11-libgstreamer-plugins-good1.0-0_1.14.5-0ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking libgstreamer-plugins-good1.0-0:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Selecting previously unselected package libshout3:amd64.\n",
      "Preparing to unpack .../12-libshout3_2.4.1-2build1_amd64.deb ...\n",
      "Unpacking libshout3:amd64 (2.4.1-2build1) ...\n",
      "Selecting previously unselected package libtag1v5-vanilla:amd64.\n",
      "Preparing to unpack .../13-libtag1v5-vanilla_1.11.1+dfsg.1-0.2build2_amd64.deb ...\n",
      "Unpacking libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-0.2build2) ...\n",
      "Selecting previously unselected package libtag1v5:amd64.\n",
      "Preparing to unpack .../14-libtag1v5_1.11.1+dfsg.1-0.2build2_amd64.deb ...\n",
      "Unpacking libtag1v5:amd64 (1.11.1+dfsg.1-0.2build2) ...\n",
      "Selecting previously unselected package libv4lconvert0:amd64.\n",
      "Preparing to unpack .../15-libv4lconvert0_1.14.2-1_amd64.deb ...\n",
      "Unpacking libv4lconvert0:amd64 (1.14.2-1) ...\n",
      "Selecting previously unselected package libv4l-0:amd64.\n",
      "Preparing to unpack .../16-libv4l-0_1.14.2-1_amd64.deb ...\n",
      "Unpacking libv4l-0:amd64 (1.14.2-1) ...\n",
      "Selecting previously unselected package gstreamer1.0-plugins-good:amd64.\n",
      "Preparing to unpack .../17-gstreamer1.0-plugins-good_1.14.5-0ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking gstreamer1.0-plugins-good:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Selecting previously unselected package liba52-0.7.4:amd64.\n",
      "Preparing to unpack .../18-liba52-0.7.4_0.7.4-19_amd64.deb ...\n",
      "Unpacking liba52-0.7.4:amd64 (0.7.4-19) ...\n",
      "Selecting previously unselected package libdvdread4:amd64.\n",
      "Preparing to unpack .../19-libdvdread4_6.0.0-1_amd64.deb ...\n",
      "Unpacking libdvdread4:amd64 (6.0.0-1) ...\n",
      "Selecting previously unselected package libmpeg2-4:amd64.\n",
      "Preparing to unpack .../20-libmpeg2-4_0.5.1-8_amd64.deb ...\n",
      "Unpacking libmpeg2-4:amd64 (0.5.1-8) ...\n",
      "Selecting previously unselected package libsidplay1v5:amd64.\n",
      "Preparing to unpack .../21-libsidplay1v5_1.36.59-11_amd64.deb ...\n",
      "Unpacking libsidplay1v5:amd64 (1.36.59-11) ...\n",
      "Selecting previously unselected package gstreamer1.0-plugins-ugly:amd64.\n",
      "Preparing to unpack .../22-gstreamer1.0-plugins-ugly_1.14.5-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking gstreamer1.0-plugins-ugly:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package gstreamer1.0-tools.\n",
      "Preparing to unpack .../23-gstreamer1.0-tools_1.14.5-0ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking gstreamer1.0-tools (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Selecting previously unselected package libgstreamer-gl1.0-0:amd64.\n",
      "Preparing to unpack .../24-libgstreamer-gl1.0-0_1.14.5-0ubuntu1~18.04.3_amd64.deb ...\n",
      "Unpacking libgstreamer-gl1.0-0:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Selecting previously unselected package libgstreamer-plugins-bad1.0-0:amd64.\n",
      "Preparing to unpack .../25-libgstreamer-plugins-bad1.0-0_1.14.5-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libgstreamer-plugins-bad1.0-0:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libva-wayland2:amd64.\n",
      "Preparing to unpack .../26-libva-wayland2_2.1.0-3_amd64.deb ...\n",
      "Unpacking libva-wayland2:amd64 (2.1.0-3) ...\n",
      "Selecting previously unselected package gstreamer1.0-vaapi:amd64.\n",
      "Preparing to unpack .../27-gstreamer1.0-vaapi_1.14.5-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking gstreamer1.0-vaapi:amd64 (1.14.5-0ubuntu1~ubuntu18.04.1) ...\n",
      "Selecting previously unselected package libde265-0:amd64.\n",
      "Preparing to unpack .../28-libde265-0_1.0.2-2build1_amd64.deb ...\n",
      "Unpacking libde265-0:amd64 (1.0.2-2build1) ...\n",
      "Selecting previously unselected package libdvdnav4:amd64.\n",
      "Preparing to unpack .../29-libdvdnav4_6.0.0-1_amd64.deb ...\n",
      "Unpacking libdvdnav4:amd64 (6.0.0-1) ...\n",
      "Selecting previously unselected package libfaac0:amd64.\n",
      "Preparing to unpack .../30-libfaac0_1.29.7.7-1_amd64.deb ...\n",
      "Unpacking libfaac0:amd64 (1.29.7.7-1) ...\n",
      "Selecting previously unselected package libfaad2:amd64.\n",
      "Preparing to unpack .../31-libfaad2_2.8.8-1_amd64.deb ...\n",
      "Unpacking libfaad2:amd64 (2.8.8-1) ...\n",
      "Selecting previously unselected package libfluidsynth1:amd64.\n",
      "Preparing to unpack .../32-libfluidsynth1_1.1.9-1_amd64.deb ...\n",
      "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Selecting previously unselected package libgssdp-1.0-3:amd64.\n",
      "Preparing to unpack .../33-libgssdp-1.0-3_1.0.2-2_amd64.deb ...\n",
      "Unpacking libgssdp-1.0-3:amd64 (1.0.2-2) ...\n",
      "Selecting previously unselected package libgupnp-1.0-4:amd64.\n",
      "Preparing to unpack .../34-libgupnp-1.0-4_1.0.2-2_amd64.deb ...\n",
      "Unpacking libgupnp-1.0-4:amd64 (1.0.2-2) ...\n",
      "Selecting previously unselected package libgupnp-igd-1.0-4:amd64.\n",
      "Preparing to unpack .../35-libgupnp-igd-1.0-4_0.2.5-1_amd64.deb ...\n",
      "Unpacking libgupnp-igd-1.0-4:amd64 (0.2.5-1) ...\n",
      "Selecting previously unselected package libkate1:amd64.\n",
      "Preparing to unpack .../36-libkate1_0.4.1-7build1_amd64.deb ...\n",
      "Unpacking libkate1:amd64 (0.4.1-7build1) ...\n",
      "Selecting previously unselected package libserd-0-0:amd64.\n",
      "Preparing to unpack .../37-libserd-0-0_0.28.0~dfsg0-1_amd64.deb ...\n",
      "Unpacking libserd-0-0:amd64 (0.28.0~dfsg0-1) ...\n",
      "Selecting previously unselected package libsord-0-0:amd64.\n",
      "Preparing to unpack .../38-libsord-0-0_0.16.0~dfsg0-1_amd64.deb ...\n",
      "Unpacking libsord-0-0:amd64 (0.16.0~dfsg0-1) ...\n",
      "Selecting previously unselected package libsratom-0-0:amd64.\n",
      "Preparing to unpack .../39-libsratom-0-0_0.6.0~dfsg0-1_amd64.deb ...\n",
      "Unpacking libsratom-0-0:amd64 (0.6.0~dfsg0-1) ...\n",
      "Selecting previously unselected package liblilv-0-0.\n",
      "Preparing to unpack .../40-liblilv-0-0_0.24.2~dfsg0-1_amd64.deb ...\n",
      "Unpacking liblilv-0-0 (0.24.2~dfsg0-1) ...\n",
      "Selecting previously unselected package libmjpegutils-2.1-0.\n",
      "Preparing to unpack .../41-libmjpegutils-2.1-0_1%3a2.1.0+debian-5_amd64.deb ...\n",
      "Unpacking libmjpegutils-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Selecting previously unselected package libmms0:amd64.\n",
      "Preparing to unpack .../42-libmms0_0.6.4-2_amd64.deb ...\n",
      "Unpacking libmms0:amd64 (0.6.4-2) ...\n",
      "Selecting previously unselected package libmodplug1:amd64.\n",
      "Preparing to unpack .../43-libmodplug1_1%3a0.8.9.0-1_amd64.deb ...\n",
      "Unpacking libmodplug1:amd64 (1:0.8.9.0-1) ...\n",
      "Selecting previously unselected package libmpcdec6:amd64.\n",
      "Preparing to unpack .../44-libmpcdec6_2%3a0.1~r495-1_amd64.deb ...\n",
      "Unpacking libmpcdec6:amd64 (2:0.1~r495-1) ...\n",
      "Selecting previously unselected package libmpeg2encpp-2.1-0.\n",
      "Preparing to unpack .../45-libmpeg2encpp-2.1-0_1%3a2.1.0+debian-5_amd64.deb ...\n",
      "Unpacking libmpeg2encpp-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Selecting previously unselected package libmplex2-2.1-0.\n",
      "Preparing to unpack .../46-libmplex2-2.1-0_1%3a2.1.0+debian-5_amd64.deb ...\n",
      "Unpacking libmplex2-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Selecting previously unselected package libnice10:amd64.\n",
      "Preparing to unpack .../47-libnice10_0.1.14-1_amd64.deb ...\n",
      "Unpacking libnice10:amd64 (0.1.14-1) ...\n",
      "Selecting previously unselected package libofa0:amd64.\n",
      "Preparing to unpack .../48-libofa0_0.9.3-15_amd64.deb ...\n",
      "Unpacking libofa0:amd64 (0.9.3-15) ...\n",
      "Selecting previously unselected package libsoundtouch1:amd64.\n",
      "Preparing to unpack .../49-libsoundtouch1_1.9.2-3_amd64.deb ...\n",
      "Unpacking libsoundtouch1:amd64 (1.9.2-3) ...\n",
      "Selecting previously unselected package libspandsp2:amd64.\n",
      "Preparing to unpack .../50-libspandsp2_0.0.6+dfsg-0.1_amd64.deb ...\n",
      "Unpacking libspandsp2:amd64 (0.0.6+dfsg-0.1) ...\n",
      "Selecting previously unselected package libsrtp2-1:amd64.\n",
      "Preparing to unpack .../51-libsrtp2-1_2.1.0-1_amd64.deb ...\n",
      "Unpacking libsrtp2-1:amd64 (2.1.0-1) ...\n",
      "Selecting previously unselected package libtag-extras1.\n",
      "Preparing to unpack .../52-libtag-extras1_1.0.1-3.1_amd64.deb ...\n",
      "Unpacking libtag-extras1 (1.0.1-3.1) ...\n",
      "Selecting previously unselected package libvulkan1:amd64.\n",
      "Preparing to unpack .../53-libvulkan1_1.1.126.0-2~gpu18.04.1_amd64.deb ...\n",
      "Unpacking libvulkan1:amd64 (1.1.126.0-2~gpu18.04.1) ...\n",
      "Selecting previously unselected package libwebrtc-audio-processing1:amd64.\n",
      "Preparing to unpack .../54-libwebrtc-audio-processing1_0.3-1_amd64.deb ...\n",
      "Unpacking libwebrtc-audio-processing1:amd64 (0.3-1) ...\n",
      "Selecting previously unselected package libwildmidi-config.\n",
      "Preparing to unpack .../55-libwildmidi-config_0.4.2-1_all.deb ...\n",
      "Unpacking libwildmidi-config (0.4.2-1) ...\n",
      "Selecting previously unselected package libwildmidi2:amd64.\n",
      "Preparing to unpack .../56-libwildmidi2_0.4.2-1_amd64.deb ...\n",
      "Unpacking libwildmidi2:amd64 (0.4.2-1) ...\n",
      "Selecting previously unselected package libzbar0:amd64.\n",
      "Preparing to unpack .../57-libzbar0_0.10+doc-10.1build2_amd64.deb ...\n",
      "Unpacking libzbar0:amd64 (0.10+doc-10.1build2) ...\n",
      "Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../58-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
      "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
      "Selecting previously unselected package python3-pip.\n",
      "Preparing to unpack .../59-python3-pip_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
      "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
      "Selecting previously unselected package python3-pkg-resources.\n",
      "Preparing to unpack .../60-python3-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python3-setuptools.\n",
      "Preparing to unpack .../61-python3-setuptools_39.0.1-2_all.deb ...\n",
      "Unpacking python3-setuptools (39.0.1-2) ...\n",
      "Selecting previously unselected package python3.6-venv.\n",
      "Preparing to unpack .../62-python3.6-venv_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\n",
      "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Selecting previously unselected package python3-venv.\n",
      "Preparing to unpack .../63-python3-venv_3.6.7-1~18.04_amd64.deb ...\n",
      "Unpacking python3-venv (3.6.7-1~18.04) ...\n",
      "Selecting previously unselected package vainfo.\n",
      "Preparing to unpack .../64-vainfo_2.1.0+ds1-1_amd64.deb ...\n",
      "Unpacking vainfo (2.1.0+ds1-1) ...\n",
      "Selecting previously unselected package libdca0:amd64.\n",
      "Preparing to unpack .../65-libdca0_0.0.5-10_amd64.deb ...\n",
      "Unpacking libdca0:amd64 (0.0.5-10) ...\n",
      "Selecting previously unselected package libsbc1:amd64.\n",
      "Preparing to unpack .../66-libsbc1_1.3-2_amd64.deb ...\n",
      "Unpacking libsbc1:amd64 (1.3-2) ...\n",
      "Selecting previously unselected package gstreamer1.0-plugins-bad:amd64.\n",
      "Preparing to unpack .../67-gstreamer1.0-plugins-bad_1.14.5-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking gstreamer1.0-plugins-bad:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Setting up libvulkan1:amd64 (1.1.126.0-2~gpu18.04.1) ...\n",
      "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
      "Setting up libsbc1:amd64 (1.3-2) ...\n",
      "Setting up libmpeg2-4:amd64 (0.5.1-8) ...\n",
      "Setting up libfaac0:amd64 (1.29.7.7-1) ...\n",
      "Setting up libmms0:amd64 (0.6.4-2) ...\n",
      "Setting up libsidplay1v5:amd64 (1.36.59-11) ...\n",
      "Setting up libmodplug1:amd64 (1:0.8.9.0-1) ...\n",
      "Setting up libde265-0:amd64 (1.0.2-2build1) ...\n",
      "Setting up libmpcdec6:amd64 (2:0.1~r495-1) ...\n",
      "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
      "Setting up libgpm2:amd64 (1.20.7-5) ...\n",
      "Setting up libcap2-bin (1:2.25-1.2) ...\n",
      "Setting up libv4lconvert0:amd64 (1.14.2-1) ...\n",
      "Setting up libwebrtc-audio-processing1:amd64 (0.3-1) ...\n",
      "Setting up libva-wayland2:amd64 (2.1.0-3) ...\n",
      "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Setting up libfaad2:amd64 (2.8.8-1) ...\n",
      "Setting up libkate1:amd64 (0.4.1-7build1) ...\n",
      "Setting up vainfo (2.1.0+ds1-1) ...\n",
      "Setting up libspandsp2:amd64 (0.0.6+dfsg-0.1) ...\n",
      "Setting up m4 (1.4.18-1) ...\n",
      "Setting up python3-pkg-resources (39.0.1-2) ...\n",
      "Setting up libcdparanoia0:amd64 (3.10.2+debian-13) ...\n",
      "Setting up libvo-aacenc0:amd64 (0.1.3-1) ...\n",
      "Setting up libgssdp-1.0-3:amd64 (1.0.2-2) ...\n",
      "Setting up libwildmidi-config (0.4.2-1) ...\n",
      "Setting up liba52-0.7.4:amd64 (0.7.4-19) ...\n",
      "Setting up libmjpegutils-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Setting up libvo-amrwbenc0:amd64 (0.1.3-1) ...\n",
      "Setting up libaa1:amd64 (1.4p5-44build2) ...\n",
      "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
      "Setting up libofa0:amd64 (0.9.3-15) ...\n",
      "Setting up libvisual-0.4-0:amd64 (0.4.0-11) ...\n",
      "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
      "Setting up liborc-0.4-0:amd64 (1:0.4.28-1) ...\n",
      "Setting up libsrtp2-1:amd64 (2.1.0-1) ...\n",
      "Setting up libsoundtouch1:amd64 (1.9.2-3) ...\n",
      "Setting up python3-setuptools (39.0.1-2) ...\n",
      "Setting up libdca0:amd64 (0.0.5-10) ...\n",
      "Setting up libserd-0-0:amd64 (0.28.0~dfsg0-1) ...\n",
      "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
      "Setting up libshout3:amd64 (2.4.1-2build1) ...\n",
      "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Setting up libmplex2-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Setting up libdv4:amd64 (1.0.0-11) ...\n",
      "Setting up libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-0.2build2) ...\n",
      "Setting up libdvdread4:amd64 (6.0.0-1) ...\n",
      "Setting up python3-venv (3.6.7-1~18.04) ...\n",
      "Setting up libmpeg2encpp-2.1-0 (1:2.1.0+debian-5) ...\n",
      "Setting up libtag1v5:amd64 (1.11.1+dfsg.1-0.2build2) ...\n",
      "Setting up libgstreamer1.0-0:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Setcap worked! gst-ptp-helper is not suid!\n",
      "Setting up libgupnp-1.0-4:amd64 (1.0.2-2) ...\n",
      "Setting up libv4l-0:amd64 (1.14.2-1) ...\n",
      "Setting up flex (2.6.4-6) ...\n",
      "Setting up libdvdnav4:amd64 (6.0.0-1) ...\n",
      "Setting up libsord-0-0:amd64 (0.16.0~dfsg0-1) ...\n",
      "Setting up libwildmidi2:amd64 (0.4.2-1) ...\n",
      "Setting up libgupnp-igd-1.0-4:amd64 (0.2.5-1) ...\n",
      "Setting up gstreamer1.0-tools (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Setting up libnice10:amd64 (0.1.14-1) ...\n",
      "Setting up libtag-extras1 (1.0.1-3.1) ...\n",
      "Setting up libgstreamer-plugins-base1.0-0:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Setting up libsratom-0-0:amd64 (0.6.0~dfsg0-1) ...\n",
      "Setting up gstreamer1.0-plugins-base:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Setting up liblilv-0-0 (0.24.2~dfsg0-1) ...\n",
      "Setting up libzbar0:amd64 (0.10+doc-10.1build2) ...\n",
      "Setting up libgstreamer-gl1.0-0:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Setting up libgstreamer-plugins-bad1.0-0:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Setting up gstreamer1.0-vaapi:amd64 (1.14.5-0ubuntu1~ubuntu18.04.1) ...\n",
      "Setting up gstreamer1.0-plugins-ugly:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Setting up libgstreamer-plugins-good1.0-0:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Setting up gstreamer1.0-alsa:amd64 (1.14.5-0ubuntu1~18.04.3) ...\n",
      "Setting up gstreamer1.0-plugins-bad:amd64 (1.14.5-0ubuntu1~18.04.1) ...\n",
      "Setting up gstreamer1.0-plugins-good:amd64 (1.14.5-0ubuntu1~18.04.2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r2enKxK_qakX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa4b139c-cf87-4212-ae96-a7d87f39ca44"
   },
   "source": [
    "!ls"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "EULA.txt\tinstall_openvino_dependencies.sh  pset\t\t  rpm\n",
      "install_GUI.sh\tinstall.sh\t\t\t  PUBLIC_KEY.PUB  silent.cfg\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-jbjiw-7nAv"
   },
   "source": [
    "[Optional] Open Vino install check, generally not needed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0NJp28Oj7Ts9"
   },
   "source": [
    "# !source /opt/intel/openvino/bin/setupvars.sh && \\\n",
    "#     /opt/intel/openvino/deployment_tools/demo/demo_squeezenet_download_convert_run.sh"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TygLw4WIO8BD"
   },
   "source": [
    "### Here we run some modifications in the ssd2 OpenVINO extension for TF so that our Mobilenet SSDv2 model can convert successfully to the IR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P-bGZHGcMNbZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0fce1d46-e69c-4cbf-b608-65bc5898b909"
   },
   "source": [
    "%cd /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/\n",
    "\n",
    "#openvino fixes: edit \n",
    "# Read in the file, make sure the .json corresponds to the model!!!\n",
    "with open('ssd_v2_support.json', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n",
    "\n",
    "# Write the file out again\n",
    "with open('ssd_v2_support.json', 'w') as file:\n",
    "  file.write(filedata)\n"
   ],
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/opt/intel/openvino_2021.3.394/deployment_tools/model_optimizer/extensions/front/tf\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7sqTX79W6hh"
   },
   "source": [
    "## Convert TF model to Open Vino Intermediate Representation\n",
    "If using own model, please change to your desired name for output directory --output_dir \"choose name\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LsWggE5AIWS6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a4163f3f-e89e-4d98-99d4-87e694556a64"
   },
   "source": [
    "#CONVERT TF MODEL to OPEN VINO IRv10. saved in IR_V10_fruits_mnssdv2_6k directory or\n",
    "#choose own name for --output_dir \"choose name\"\n",
    "%cd \"/content/models/research/fine_tuned_model/\"\n",
    "!source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n",
    "    python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n",
    "    --input_model frozen_inference_graph.pb \\\n",
    "    --tensorflow_use_custom_operations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
    "    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
    "    --reverse_input_channels \\\n",
    "    --output_dir ./fruits_10k \\\n",
    "    --data_type FP16"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/models/research/fine_tuned_model\n",
      "error: XDG_RUNTIME_DIR not set in the environment.\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "[ WARNING ]  Use of deprecated cli option --tensorflow_use_custom_operations_config detected. Option use in the following releases will be fatal. Please use --transformations_config cli option instead\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/content/models/research/fine_tuned_model/frozen_inference_graph.pb\n",
      "\t- Path for generated IR: \t/content/models/research/fine_tuned_model/./fruits_10k\n",
      "\t- IR output name: \tfrozen_inference_graph\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \t/content/models/research/fine_tuned_model/pipeline.config\n",
      "\t- Use the config file: \t/opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
      "\t- Inference Engine found in: \t/opt/intel/openvino_2021/python/python3.7/openvino\n",
      "Inference Engine version: \t2.1.2021.3.0-2787-60059f2c755-releases/2021/3\n",
      "Model Optimizer version: \t    2021.3.0-2787-60059f2c755-releases/2021/3\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\ttest-generator: not installed, required: == 0.1.1\n",
      "\n",
      "Please install required versions of components or use install_prerequisites script\n",
      "/opt/intel/openvino_2021.3.394/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites_tf.sh\n",
      "Note that install_prerequisites scripts may install additional components.\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.xml\n",
      "[ SUCCESS ] BIN file: /content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.bin\n",
      "[ SUCCESS ] Total execution time: 47.25 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1167 MB. \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o9R7LTkNvZos"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P15Hl-Fbmkib",
    "outputId": "8b60ec22-9e5f-44af-85e4-4ecb60547836",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#check directory containing the exported TF trained model and the IRv10 folder\n",
    "%ls fruits_10k/"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "frozen_inference_graph.bin      frozen_inference_graph.xml\n",
      "frozen_inference_graph.mapping\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD2BMtXoPjYN"
   },
   "source": [
    "## Now we compile the IR model to a .blob for use on DepthAI modules/platform\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqZqajTIP3Sv"
   },
   "source": [
    "### We save the blob in the IR directory from above, corresponding to --output_dir parameter above. \n",
    "The blob filename will be *frozen_inference_graph.blob*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IqiPpnCwPioH",
    "outputId": "92675214-c9d9-4c4e-a20c-2f299c90527f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    }
   },
   "source": [
    "#No changes needed here unless using custom data.\n",
    "#CHOOSE the directory where you would like to save the blob.\n",
    "# I use the same --output_dir as above for the IR conversion\n",
    "blob_dir = \"/content/models/research/fine_tuned_model/fruits_10k/\"\n",
    "\n",
    "#Copy the path of your .xml and .bin files. For that, you can look at the IR\n",
    "#conversion output cell, select and copy from:\n",
    "#[SUCCESS] XML file and bin file paths.\n",
    "#Or you can choose to compile other .xml .bin files from a different location\n",
    "#\n",
    "xmlfile = \"/content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.xml\"\n",
    "binfile = \"/content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.bin\"\n",
    "!python -m pip install blobconverter\n",
    "\n",
    "import blobconverter\n",
    "blob_path = blobconverter.from_openvino(\n",
    "    xml=xmlfile,\n",
    "    bin=binfile,\n",
    "    data_type=\"FP16\",\n",
    "    shaves=5,\n",
    ")\n",
    "from google.colab import files\n",
    "files.download(blob_path) "
   ],
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting blobconverter\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/17/5b50c0a91c423f56401fec40241157ef05bab52f7020d679b4608bf5dd2a/blobconverter-0.0.10-py3-none-any.whl\n",
      "Collecting boto3\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/c8/63/92fce440b90de847cb31298c0f55865f4ebd6ba0335a21528b264ba77fdc/boto3-1.17.85-py2.py3-none-any.whl (131kB)\n",
      "\u001B[K     || 133kB 3.0MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from blobconverter) (2.23.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from blobconverter) (3.13)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.5.0,>=0.4.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
      "\u001B[K     || 81kB 6.0MB/s \n",
      "\u001B[?25hCollecting botocore<1.21.0,>=1.20.85\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/83/65/f12545664d159aaf5b464b3b2ad724035802b1ffa0f4062773c8841f9297/botocore-1.20.85-py2.py3-none-any.whl (7.6MB)\n",
      "\u001B[K     || 7.6MB 13.9MB/s \n",
      "\u001B[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->blobconverter) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->blobconverter) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->blobconverter) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->blobconverter) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.85->boto3->blobconverter) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.85->boto3->blobconverter) (1.15.0)\n",
      "\u001B[31mERROR: botocore 1.20.85 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001B[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, blobconverter\n",
      "Successfully installed blobconverter-0.0.10 boto3-1.17.85 botocore-1.20.85 jmespath-0.10.0 s3transfer-0.4.2\n",
      "Downloading /root/.cache/blobconverter/frozen_inference_graph_openvino_2021.3_5shave.blob...\n",
      "Downloading /root/.cache/blobconverter/frozen_inference_graph_openvino_2021.3_5shave.blob...\n",
      "[==================================================]\n",
      "Done\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "download(\"download_c4225659-b997-45c5-87c0-ed5fd4fd7ed5\", \"frozen_inference_graph_openvino_2021.3_5shave.blob\", 13490368)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4hQdGwQSxP0"
   },
   "source": [
    "##Now you can download your .blob file and run it on the DepthAI module/platform\n",
    "To download locally, use the file explorer on the left to locate the file in the --output_dir folder, then right click download. Colab takes a few seconds to prepare the file, then the download prompt will appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24-2kaAFvyEd"
   },
   "source": [
    "# Run the blob on DepthAI\n",
    "\n",
    "To use this blob with DepthAI:\n",
    "\n",
    "- Clone depthai demo script\n",
    "\n",
    "    ```\n",
    "    $ git clone https://github.com/luxonis/depthai.git\n",
    "    ```\n",
    "- Install requirements\n",
    "\n",
    "    ```\n",
    "    $ python3 install_requirements.py\n",
    "    ```\n",
    "- Create a new model directory and insert the blob\n",
    "\n",
    "    ```\n",
    "    $ mkdir resources/nn/custom_mobilenet\n",
    "    $ mv <downloaded_blob> resources/nn/custom_mobilenet/\n",
    "    ```\n",
    "\n",
    "- Copy config file from mobilenet-ssd model\n",
    "\n",
    "    ```\n",
    "    $ cp resources/nn/mobilenet-ssd/mobilenet-ssd.json resources/nn/custom_mobilenet/custom_mobilenet.json\n",
    "    ```\n",
    "\n",
    "- Run the demo script\n",
    "\n",
    "    ```\n",
    "    $ python3 depthai_demo.py -cnn custom_mobilenet\n",
    "    ```\n",
    "\n",
    "You can read more details on deployment [here](https://docs.luxonis.com/en/latest/pages/tutorials/first_steps/#using-custom-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ig_1EilKakAh"
   },
   "source": [
    "##[Optional] to convert the blob locally, download the IR files .bin and .xml and follow these instructions: \n",
    "https://docs.luxonis.com/en/latest/pages/tutorials/local_convert_openvino/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U18F9dvOLs1I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ff953b49-a5b6-4149-c383-d70eba37311d"
   },
   "source": [
    "#Compress the folder with the Tensorflow model and OpenVINO IR_V10 folder and download it locally.\n",
    "#These are in content/models/research/fine_tuned_model, so we compress the fine_tuned_model folder.\n",
    "!tar czvf fine_tuned_model.tar.gz {blob_dir}\n"
   ],
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\n",
      "/content/models/research/fine_tuned_model/fruits_10k/\n",
      "/content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.bin\n",
      "/content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.mapping\n",
      "/content/models/research/fine_tuned_model/fruits_10k/frozen_inference_graph.xml\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YARGCLW7KJxo"
   },
   "source": [
    "#download the compressed IRv10 folder locally\n",
    "#or can use file navigator on the left to move it to your gdrive\n",
    "from google.colab import files\n",
    "files.download(\"fine_tuned_model.tar.gz\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qyl2PyyVnQwH"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}